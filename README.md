# Machine Learning Algorithms & Techniques

This repository contains a collection of Jupyter notebooks demonstrating key machine learning algorithms, from classical statistical models to modern deep learning techniques. It covers supervised learning, unsupervised learning, probabilistic models, ensemble methods, and neural networks for text and image data.

It demonstrates:
- Supervised vs. unsupervised learning
- Probabilistic models and statistical inference
- Ensemble methods (bagging & boosting)
- Neural networks (MLP, CNN concepts, RNNs)
- Text, image, and numerical data pipelines
- From-scratch implementations and library-based workflows

---

## Quick Overview

### Linear Regression Wine Quality Example.ipynb
Implements linear regression to predict wine quality from numerical features. Demonstrates feature–target relationships, least squares fitting, and regression evaluation.

**Techniques:** Linear regression, continuous prediction

---

### Bayes' Theorem and Naive Bayes Spam Classifier.ipynb
Introduces Bayes’ Theorem and applies Naive Bayes to a spam classification task. Emphasizes probabilistic reasoning and conditional independence assumptions.

**Techniques:** Bayes’ Theorem, Naive Bayes, text classification

---

### Multinomial Naive Bayes classifier.ipynb
Uses Multinomial Naive Bayes for text classification with Bag-of-Words features. Demonstrates a complete NLP pipeline from vectorization to prediction.

**Techniques:** Multinomial Naive Bayes, Bag-of-Words, NLP

---

### AdaBoost Breast Cancer Example.ipynb
Applies the AdaBoost algorithm to a breast cancer dataset. Demonstrates boosting through iterative reweighting of misclassified samples.

**Techniques:** AdaBoost, boosting, ensemble learning

---

### Random Forest.ipynb
Implements a Random Forest classifier using an ensemble of decision trees. Demonstrates bootstrap sampling, feature randomness, and improved generalization.

**Techniques:** Random Forest, bagging, ensemble methods

---

### MLP Classifier.ipynb
Implements a Multi-Layer Perceptron (MLP) for classification. Covers hidden layers, nonlinear activation functions, and gradient-based optimization.

**Techniques:** Feedforward neural networks, backpropagation

---

### Kmeans by Hand.ipynb
Implements the K-Means clustering algorithm from scratch to illustrate centroid initialization, assignment, and update steps.

**Techniques:** K-Means, unsupervised learning, clustering

---

### Unsupervised ML Kmeans.ipynb
Applies K-Means clustering using library implementations. Focuses on unsupervised learning workflows and interpretation of clusters.

**Techniques:** K-Means, unsupervised ML

---

### Kmeans Image Practice.ipynb
Uses K-Means clustering for image color quantization, demonstrating how clustering can be applied to image compression.

**Techniques:** Image clustering, vector quantization

---

### CNN Filter.ipynb
Explores convolutional filters used in convolutional neural networks. Demonstrates how kernels extract edges and local spatial features.

**Techniques:** Convolution, CNN fundamentals, image processing

---

### Numpy Noise Reduction Example.ipynb
Demonstrates noise reduction techniques using NumPy operations. Applies numerical filtering to smooth noisy data.

**Techniques:** Noise reduction, numerical methods, signal processing

---

### mnist.ipynb
Applies machine learning techniques to the MNIST handwritten digit dataset. Covers preprocessing and classification.

**Techniques:** Image classification, MNIST, supervised learning

---

### mnist2.ipynb
A continuation or alternative approach to MNIST digit classification, exploring different modeling or preprocessing strategies.

**Techniques:** Neural networks, image classification

---

### RNN.ipynb
Introduces Recurrent Neural Networks (RNNs) for sequence modeling. Demonstrates how temporal dependencies are handled in sequential data.

**Techniques:** RNNs, sequence modeling

---

### RNN with Tensorflow Keras IMDb Example.ipynb
Uses TensorFlow/Keras to implement an RNN for sentiment analysis on the IMDb dataset. Demonstrates deep learning for text sequences.

**Techniques:** RNNs, NLP, TensorFlow/Keras

---
